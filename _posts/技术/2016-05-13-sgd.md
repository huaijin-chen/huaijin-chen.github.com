---
layout: post
title: Caffe中的随机梯度优化算法
categories: 技术
tags: DeepLearning Optimization Caffe


---

##前言
在Deep learning中使用最多是随机梯度，本文主要结合Caffe的源码对的随机梯度优化方法进行简单的总结。学习随机梯度算法的同时阅读源码。 
Caffe中使用的solver有一下几种：

 - Stochastic Gradient Descent (type: "SGD")；
 - AdaDelta (type: "AdaDelta")；
 - Adaptive Gradient (type: "AdaGrad")；
 - Adam (type: "Adam")；
 - Nesterov’s Accelerated Gradient (type: "Nesterov")；
 - RMSprop (type: "RMSProp"). 

在这里主要分析最常用的Stochastic Gradient Descent的实现。
 
## Stochastic Gradient Descent

$$ V_{t+1} = \mu V_t - \alpha \nabla L(W_t) $$

$$ W_{t+1} = W_t + V_{t+1} $$

其中$\mu$ 是momentu, $\alpha$ 是学习率；$\nabla L(W)$ 是权重的梯度。$V_{t+1}$是$t+1$次的更新量.

{% highlight  C++%}
template <typename Dtype>
void SGDSolver<Dtype>::ComputeUpdateValue(int param_id, Dtype rate) {
  const vector<Blob<Dtype>*>& net_params = this->net_->learnable_params();
  const vector<float>& net_params_lr = this->net_->params_lr();
  Dtype momentum = this->param_.momentum();
  Dtype local_rate = rate * net_params_lr[param_id];
  // Compute the update to history, then copy it to the parameter diff.
  switch (Caffe::mode()) {
  case Caffe::CPU: {
  //这里是按照$W_t+1 = momentum*W_t + learningRate* \deta L(W_t)$  
  //实现的， 没有完全按照上面的公式实现
    caffe_cpu_axpby(net_params[param_id]->count(), local_rate,
              net_params[param_id]->cpu_diff(), momentum,
              history_[param_id]->mutable_cpu_data());
// 把更新之后的weights copy到 net_params. History_ 保存这次的更新
    caffe_copy(net_params[param_id]->count(),
        history_[param_id]->cpu_data(),
        net_params[param_id]->mutable_cpu_diff());
    break;
  }
  case Caffe::GPU: {
#ifndef CPU_ONLY
    sgd_update_gpu(net_params[param_id]->count(),
        net_params[param_id]->mutable_gpu_diff(),
        history_[param_id]->mutable_gpu_data(),
        momentum, local_rate);
#else
    NO_GPU;
#endif
    break;
  }
  default:
    LOG(FATAL) << "Unknown caffe mode: " << Caffe::mode();
  }
}
{% endhighlight%}
Caffe 的矩阵运算封装在math_function.cpp 中。 有时间将此文件进行整理，方便源码的阅读。 

更多的关于Caffe solver的内容参照官方文档 [solver tutorial][1]


  [1]: http://caffe.berkeleyvision.org/tutorial/solver.html
